{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNt+EN+3g56rmNEhNvsfVFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tmdoi/small-Japanese-LLM-compare/blob/main/benchMarkOrginal_v08math.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqVLjbLFxVXd"
      },
      "outputs": [],
      "source": [
        "!pip -q install \"transformers>=4.43\" accelerate torch --upgrade\n",
        "!pip -q install pandas sacrebleu rouge-score fugashi ipadic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-genai"
      ],
      "metadata": {
        "id": "MQnljuaWVBjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "# SDK 読み込み\n",
        "from google import genai\n",
        "\n",
        "# Colab Secrets から安全に取得\n",
        "api_key = userdata.get('GEMINI_API_KEY')\n",
        "\n",
        "if not api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY が定義されていません。Colab の Secrets を確認してください。\")\n",
        "\n",
        "\n",
        "client = genai.Client(api_key=api_key)"
      ],
      "metadata": {
        "id": "m4XQDIRIVZmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === (Colab セル1) セットアップ & モデル読込 ===\n",
        "try:\n",
        "    import google.colab  # noqa: F401\n",
        "    IN_COLAB = True\n",
        "except Exception:\n",
        "    IN_COLAB = False\n",
        "\n",
        "import sys, subprocess, math, time, re\n",
        "def pip_install(pkgs):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\"] + pkgs\n",
        "    print(\"Installing:\", \" \".join(pkgs))\n",
        "    subprocess.check_call(cmd)\n",
        "\n",
        "# 必要に応じて有効化してください（初回実行時など）\n",
        "# pip_install([\"transformers>=4.43\", \"accelerate\", \"torch\", \"pandas\", \"sacrebleu\", \"rouge-score\", \"fugashi\", \"ipadic\"])\n",
        "\n",
        "# ---- 以降 Python 本体 ----\n",
        "import torch, pandas as pd\n",
        "from dataclasses import dataclass\n",
        "from typing import List, Dict, Any, Tuple\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from rouge_score import rouge_scorer\n",
        "import sacrebleu\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "# 乱数固定（再現性の一助）\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "if torch.cuda.is_available():\n",
        "    torch.manual_seed(0)\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "\n",
        "# 比較対象モデル（必要に応じて変更可）\n",
        "MODELS = {\n",
        "    \"RakutenAI-2.0-mini-instruct\": \"Rakuten/RakutenAI-2.0-mini-instruct\",\n",
        "    \"TinySwallow-1.5B-Instruct\":   \"SakanaAI/TinySwallow-1.5B-Instruct\",\n",
        "}\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Device:\", device)\n",
        "\n",
        "@dataclass\n",
        "class GenConfig:\n",
        "    max_new_tokens: int = 256\n",
        "    temperature: float = 0.0   # 再現性重視\n",
        "    top_p: float = 1.0\n",
        "    do_sample: bool = False\n",
        "    num_beams: int = 1\n",
        "\n",
        "GENCFG = GenConfig()\n",
        "\n",
        "def load_model(repo_id: str) -> Tuple[AutoTokenizer, AutoModelForCausalLM]:\n",
        "    tok = AutoTokenizer.from_pretrained(repo_id, use_fast=True)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        repo_id,\n",
        "        torch_dtype=\"auto\",\n",
        "        device_map=\"auto\",   # ColabのGPUに自動割当\n",
        "    )\n",
        "    return tok, model\n",
        "\n",
        "def chat_generate(tokenizer, model, messages: List[Dict[str, str]], cfg: GenConfig = GENCFG):\n",
        "    # 各モデルのchatテンプレートを利用\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        messages, add_generation_prompt=True, return_tensors=\"pt\"\n",
        "    ).to(model.device)\n",
        "\n",
        "    attn = None\n",
        "    if tokenizer.pad_token_id is not None:\n",
        "        attn = input_ids.ne(tokenizer.pad_token_id).long()\n",
        "\n",
        "    t0 = time.perf_counter()\n",
        "    with torch.no_grad():\n",
        "        out_ids = model.generate(\n",
        "            input_ids,\n",
        "            max_new_tokens=cfg.max_new_tokens,\n",
        "            do_sample=cfg.do_sample,\n",
        "            temperature=cfg.temperature,\n",
        "            top_p=cfg.top_p,\n",
        "            num_beams=cfg.num_beams,\n",
        "            attention_mask=attn,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "    dt = time.perf_counter() - t0\n",
        "    gen_ids = out_ids[:, input_ids.shape[1]:]\n",
        "    text = tokenizer.batch_decode(gen_ids, skip_special_tokens=True)[0].strip()\n",
        "    toks = gen_ids.shape[1]\n",
        "    tps = toks / dt if dt > 0 else float(\"nan\")\n",
        "    return text, {\"latency_sec\": dt, \"gen_tokens\": toks, \"tok_per_sec\": tps}\n",
        "\n",
        "# タスク定義（自動採点可能なもの中心）\n",
        "TASKS = [\n",
        "    {\n",
        "        \"name\": \"JA-QA: 富士山の標高\",\n",
        "        \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"あなたは有能な日本語アシスタントです。\"},\n",
        "            {\"role\":\"user\",\"content\":\"富士山の標高は？数値と単位で簡潔に答えてください。\"}\n",
        "        ],\n",
        "        # 3776 を数値として含めれば正解扱い（ゆるい判定）\n",
        "        \"judge\": lambda x: (\"3776\" in re.sub(r\"[^\\d]\", \"\", x)) or (\"3,776\" in x) or (\"3776 m\" in x) or (\"3776メートル\" in x),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"算数: 12×(7+5)\",\n",
        "        \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "            {\"role\":\"user\",\"content\":\"12×(7+5) の結果だけを半角数字で答えてください。\"}\n",
        "        ],\n",
        "        \"judge\": lambda x: \"144\" in re.sub(r\"[^\\d\\-]\", \"\", x),\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"要約: 5文→1文\",\n",
        "        \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"与えられた段落を1文で要約してください。\"},\n",
        "            {\"role\":\"user\",\"content\":\n",
        "             \"奈良公園には多くのシカが生息し、観光客に人気です。\"\n",
        "             \"近年は観光客の増加に伴い、エサの与え方やごみ問題が課題となっています。\"\n",
        "             \"地元自治体はルール啓発と清掃活動を強化しています。\"\n",
        "             \"一方で来園者のマナー向上には時間がかかるとの指摘もあります。\"\n",
        "             \"持続可能な観光の実現に向け、地域と来訪者の協力が求められています。\"\n",
        "            }\n",
        "        ],\n",
        "        \"ref\": \"奈良公園のシカと観光をめぐる課題に対し、自治体と来訪者の協力による持続可能な観光の実現が求められている。\",\n",
        "        \"rougeL\": True\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"翻訳: EN→JA\",\n",
        "        \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"次の英文を自然な日本語に翻訳してください。\"},\n",
        "            {\"role\":\"user\",\"content\":\"Edge-friendly small LLMs enable private, low-latency applications without relying on cloud services.\"}\n",
        "        ],\n",
        "        \"ref\": \"エッジ向けの小型LLMは、クラウドサービスに依存せずにプライバシーに配慮した低遅延アプリケーションを可能にする。\",\n",
        "        \"bleu\": True\n",
        "    },\n",
        "]\n",
        "\n",
        "# ROUGE-L スコアラー（※ベンチマーク側でも参照）\n",
        "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=False)\n",
        "\n",
        "# モデル／トークナイザを事前ロードして保持（ベンチマーク側で再利用）\n",
        "print(\"\\n== Loading models ==\")\n",
        "LOADED = {}  # { model_name: (tokenizer, model) }\n",
        "for name, repo in MODELS.items():\n",
        "    print(f\"Loading: {name} ({repo})\")\n",
        "    tok, mdl = load_model(repo)\n",
        "    LOADED[name] = (tok, mdl)\n",
        "\n",
        "print(\"Loaded:\", list(LOADED.keys()))\n"
      ],
      "metadata": {
        "id": "j_3-kpBaxr3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TASKS=[\n",
        "    {\n",
        "        \"name\": \"要約: 教育\",\n",
        "        \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"与えられた段落を1文で要約してください。\"},\n",
        "            {\"role\":\"user\",\"content\":\n",
        "             \"教育は社会の基盤を支える重要な要素であり、\"\n",
        "             \"知識や技術の習得だけでなく、人間性の成長にも寄与する。\"\n",
        "             \"現代社会ではICT活用が進み、新しい学びの形が模索されている。\"\n",
        "            }\n",
        "        ],\n",
        "        \"ref\": \"教育は知識・技術と人間性の成長を支える基盤であり、ICT活用による新しい学びが求められている。\",\n",
        "        \"rougeL\": True\n",
        "    },\n",
        "    {\n",
        "        \"name\": \"翻訳: JA→EN\",\n",
        "        \"messages\": [\n",
        "            {\"role\":\"system\",\"content\":\"次の日本語を自然な英語に翻訳してください。\"},\n",
        "            {\"role\":\"user\",\"content\":\"大阪は日本で三番目に大きな都市です。\"}\n",
        "        ],\n",
        "        \"ref\": \"Osaka is the third largest city in Japan.\",\n",
        "        \"bleu\": True\n",
        "    },\n",
        "    ]"
      ],
      "metadata": {
        "id": "nSjHRt2wrmD4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === (Colab セルTaskAdd) 四則演算タスク30題を既存TASKSに追加 ===\n",
        "import re\n",
        "\n",
        "def _eq_num(ans: str, expect: str) -> bool:\n",
        "    # 半角数字・符号のみを抽出して比較（負数対応）\n",
        "    norm = re.sub(r\"[^\\d\\-]\", \"\", str(ans)).lstrip(\"+\")\n",
        "    return norm == expect\n",
        "\n",
        "EXTRA_TASKS = [\n",
        "    { \"name\": \"算数: 12+35\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"12+35 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"47\")\n",
        "    },\n",
        "    { \"name\": \"算数: 58-19\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"58-19 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"39\")\n",
        "    },\n",
        "    { \"name\": \"算数: 13×7\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"13×7 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"91\")\n",
        "    },\n",
        "    { \"name\": \"算数: 96÷12\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"96÷12 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"8\")\n",
        "    },\n",
        "    { \"name\": \"算数: 23+48-15\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"23+48-15 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"56\")\n",
        "    },\n",
        "    { \"name\": \"算数: 12×(7+5)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"12×(7+5) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"144\")\n",
        "    },\n",
        "    { \"name\": \"算数: (45-17)÷7\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(45-17)÷7 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"4\")\n",
        "    },\n",
        "    { \"name\": \"算数: 9×9+27\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"9×9+27 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"108\")\n",
        "    },\n",
        "    { \"name\": \"算数: 120÷(5×3)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"120÷(5×3) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"8\")\n",
        "    },\n",
        "    { \"name\": \"算数: 3×(14-8)+10\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"3×(14-8)+10 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"28\")\n",
        "    },\n",
        "    { \"name\": \"算数: 200-4×45\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"200-4×45 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"20\")\n",
        "    },\n",
        "    { \"name\": \"算数: (64÷8)+7×5\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(64÷8)+7×5 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"43\")\n",
        "    },\n",
        "    { \"name\": \"算数: (15+25+35)÷5\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(15+25+35)÷5 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"15\")\n",
        "    },\n",
        "    { \"name\": \"算数: 11×11-50\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"11×11-50 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"71\")\n",
        "    },\n",
        "    { \"name\": \"算数: 18÷3+27÷9\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"18÷3+27÷9 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"9\")\n",
        "    },\n",
        "    { \"name\": \"算数: (100-28)÷9\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(100-28)÷9 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"8\")\n",
        "    },\n",
        "    { \"name\": \"算数: 7×(8+6)-20\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"7×(8+6)-20 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"78\")\n",
        "    },\n",
        "    { \"name\": \"算数: 40÷(6+2)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"40÷(6+2) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"5\")\n",
        "    },\n",
        "    { \"name\": \"算数: 3×(5×4)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"3×(5×4) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"60\")\n",
        "    },\n",
        "    { \"name\": \"算数: (81÷9)×(14-11)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(81÷9)×(14-11) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"27\")\n",
        "    },\n",
        "    { \"name\": \"算数: 2×2×2×5\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"2×2×2×5 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"40\")\n",
        "    },\n",
        "    { \"name\": \"算数: 90÷(15÷3)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"90÷(15÷3) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"18\")\n",
        "    },\n",
        "    { \"name\": \"算数: 7+(48÷6)×3\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"7+(48÷6)×3 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"31\")\n",
        "    },\n",
        "    { \"name\": \"算数: (72-36)÷(9-3)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(72-36)÷(9-3) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"6\")\n",
        "    },\n",
        "    { \"name\": \"算数: 50-(3×4+2)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"50-(3×4+2) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"36\")\n",
        "    },\n",
        "    { \"name\": \"算数: (18+24+30)÷6\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(18+24+30)÷6 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"12\")\n",
        "    },\n",
        "    { \"name\": \"算数: 14×(3+2×4)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"14×(3+2×4) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"154\")\n",
        "    },\n",
        "    { \"name\": \"算数: (100÷4)÷5\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(100÷4)÷5 の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"5\")\n",
        "    },\n",
        "    { \"name\": \"算数: 8×(9-7×3)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"8×(9-7×3) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"-96\")\n",
        "    },\n",
        "    { \"name\": \"算数: (5-9)×(16÷4)\",\n",
        "      \"messages\": [\n",
        "          {\"role\":\"system\",\"content\":\"あなたは計算に正確です。\"},\n",
        "          {\"role\":\"user\",\"content\":\"(5-9)×(16÷4) の結果だけを半角数字で答えてください。\"}\n",
        "      ],\n",
        "      \"judge\": lambda x: _eq_num(x, \"-16\")\n",
        "    },\n",
        "]\n",
        "\n",
        "# 既存 TASKS に追加\n",
        "TASKS.extend(EXTRA_TASKS)\n",
        "print(f\"追加完了: TASKS は {len(TASKS)} 件になりました（今回追加: {len(EXTRA_TASKS)} 件）。\")\n"
      ],
      "metadata": {
        "id": "VOqNC5wXsZoM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 依存関係 ---\n",
        "# pip install google-genai==0.3.* rapidfuzz\n",
        "\n",
        "import os, re, json, time, hashlib, math\n",
        "from typing import List, Dict, Any, Optional\n",
        "\n",
        "# ==== 0) Gemini 初期化（AI Studio キーを環境変数で） ====\n",
        "from google import genai\n",
        "from google.genai.types import Tool, GenerateContentConfig\n",
        "\n",
        "GEMINI_MODEL = \"gemini-2.5-pro\"  # 使うモデル。必要に応じて変更\n",
        "import os\n",
        "from google import genai\n",
        "\n",
        "# シークレットから取得\n",
        "api_key = \"GEMINI_API_KEY\"\n",
        "if not api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY が Colab のシークレットに設定されていません。\")\n",
        "\n",
        "# クライアント初期化\n",
        "client = genai.Client(api_key=api_key)\n",
        "print(\"✅ Gemini API キーをシークレットから読み込みました。\")\n",
        "\n",
        "# ==== 1) キャッシュ ====\n",
        "CACHE_PATH = \"extract_cache.json\"\n",
        "try:\n",
        "    with open(CACHE_PATH, \"r\") as f:\n",
        "        EXTRACT_CACHE: Dict[str, Any] = json.load(f)\n",
        "except:\n",
        "    EXTRACT_CACHE = {}\n",
        "\n",
        "def _key(s: str) -> str:\n",
        "    return hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def _cache_get(ans: str) -> Optional[Any]:\n",
        "    return EXTRACT_CACHE.get(_key(ans))\n",
        "\n",
        "def _cache_set(ans: str, value: Any):\n",
        "    EXTRACT_CACHE[_key(ans)] = value\n",
        "\n",
        "def save_cache():\n",
        "    with open(CACHE_PATH, \"w\") as f:\n",
        "        json.dump(EXTRACT_CACHE, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "# ==== 2) まずは正規表現でローカル抽出 ====\n",
        "# - 負号、小数、分数( a/b )、百分率( % )、全角→半角 の簡易対応\n",
        "# - 複数候補があれば最後のものを採用（要件に応じてルール変更）\n",
        "zen2han = str.maketrans(\"０１２３４５６７８９－．％／\", \"0123456789-./%\")\n",
        "\n",
        "FRACTION = re.compile(r\"(-?\\d+)\\s*/\\s*(\\d+)\")\n",
        "NUMBER   = re.compile(r\"([-+]?\\d+(?:\\.\\d+)?)\")\n",
        "PERCENT  = re.compile(r\"([-+]?\\d+(?:\\.\\d+)?)\\s*%\")\n",
        "\n",
        "def local_numeric_extract(text: str) -> Optional[str]:\n",
        "    s = text.translate(zen2han)\n",
        "\n",
        "    # 明示された「答え」「最終」付近を優先（ヒューリスティック）\n",
        "    focus = None\n",
        "    for anchor in [\"答え\", \"最終\", \"結果\", \"よって\", \"したがって\"]:\n",
        "        i = s.rfind(anchor)\n",
        "        if i != -1:\n",
        "            focus = s[i:i+80]\n",
        "            break\n",
        "    target = focus or s\n",
        "\n",
        "    # 分数（a/b）優先\n",
        "    m = FRACTION.findall(target)\n",
        "    if m:\n",
        "        num, den = m[-1]\n",
        "        # 必要に応じて既約化/小数化可。ここは「表記を保つ」ため文字列で返す。\n",
        "        return f\"{num}/{den}\"\n",
        "\n",
        "    # 百分率\n",
        "    m = PERCENT.findall(target)\n",
        "    if m:\n",
        "        return m[-1]  # 例: \"12.5\"（%は落とす。必要であれば別タグで保持）\n",
        "\n",
        "    # 通常の数値\n",
        "    m = NUMBER.findall(target)\n",
        "    if m:\n",
        "        return m[-1]\n",
        "\n",
        "    # だめなら全文から拾う\n",
        "    m = FRACTION.findall(s) or PERCENT.findall(s) or NUMBER.findall(s)\n",
        "    if m:\n",
        "        if isinstance(m[0], tuple):\n",
        "            num, den = m[-1]\n",
        "            return f\"{num}/{den}\"\n",
        "        return m[-1] if isinstance(m[-1], str) else None\n",
        "\n",
        "    return None\n",
        "\n",
        "# ==== 3) Gemini でバッチ抽出（JSON で厳密に返させる） ====\n",
        "# 期待フォーマット: {\"results\": [{\"value\": \"<string or number or NA>\"} ...]}\n",
        "def gemini_extract_many(texts: List[str], max_retries=4, rpm=2) -> List[Optional[str]]:\n",
        "    # レート制限（例: 1分あたり2リクエスト）\n",
        "    # ここでは「1バッチ=1リクエスト」として守る。呼び出し側でバッチ化すること。\n",
        "    # 429時は指数バックオフ。\n",
        "    # JSONスキーマを軽く強制するため、出力形式を固定。\n",
        "\n",
        "    # プロンプト（厳格指示）\n",
        "    sys_prompt = (\n",
        "        \"あなたは日本語の数式回答から最終数値のみを抽出して返す抽出器です。\"\n",
        "        \"以下の各回答について、次のルールで結果を JSON 配列で返してください。\\n\"\n",
        "        \"ルール:\\n\"\n",
        "        \"1) 最終的な数値解のみ。単位や余分な文字は除外。\\n\"\n",
        "        \"2) 分数は 'a/b' の文字列で返す（既約化は不要）。\\n\"\n",
        "        \"3) 数値が一意に定まらなければ 'NA' を返す。\\n\"\n",
        "        \"4) 出力は JSON: {\\\"results\\\": [{\\\"value\\\": ...}, ...]} の形。\\n\"\n",
        "    )\n",
        "\n",
        "    # 入力の構築\n",
        "    items = [{\"id\": i, \"text\": t} for i, t in enumerate(texts)]\n",
        "    user_prompt = \"対象テキスト一覧:\\n\" + \"\\n\".join(\n",
        "        [f\"[{it['id']}] {it['text']}\" for it in items]\n",
        "    ) + \"\\n\\n\" + \"以上です。順番を変えずに results を返してください。\"\n",
        "\n",
        "    # 応答を JSON に限定\n",
        "    cfg = GenerateContentConfig(\n",
        "        response_mime_type=\"application/json\",\n",
        "    )\n",
        "\n",
        "    for attempt in range(max_retries):\n",
        "        try:\n",
        "            resp = client.models.generate_content(\n",
        "                model=GEMINI_MODEL,\n",
        "                contents=[{\"role\":\"user\",\"parts\":[{\"text\": sys_prompt + \"\\n\" + user_prompt}]}],\n",
        "                config=cfg,\n",
        "            )\n",
        "            data = resp.text\n",
        "            parsed = json.loads(data)\n",
        "            out = []\n",
        "            for i in range(len(texts)):\n",
        "                try:\n",
        "                    v = parsed[\"results\"][i][\"value\"]\n",
        "                    # number の場合も文字列化して整合\n",
        "                    out.append(str(v) if v is not None else None)\n",
        "                except Exception:\n",
        "                    out.append(None)\n",
        "            return out\n",
        "        except Exception as e:\n",
        "            # 429 等\n",
        "            msg = str(e)\n",
        "            if \"429\" in msg or \"RESOURCE_EXHAUSTED\" in msg:\n",
        "                wait = (2 ** attempt) * 15  # 15s, 30s, 60s, 120s...\n",
        "                time.sleep(wait)\n",
        "                continue\n",
        "            else:\n",
        "                # その他の失敗は即座に None 配列\n",
        "                return [None] * len(texts)\n",
        "\n",
        "    return [None] * len(texts)\n",
        "\n",
        "# ==== 4) 統合：まずキャッシュ→ローカル→（必要時のみ）Gemini ====\n",
        "def extract_numeric_answer(answer_text: str) -> Optional[str]:\n",
        "    if not answer_text:\n",
        "        return None\n",
        "    cached = _cache_get(answer_text)\n",
        "    if cached is not None:\n",
        "        return cached\n",
        "\n",
        "    # まずローカル抽出\n",
        "    local = local_numeric_extract(answer_text)\n",
        "    if local is not None:\n",
        "        _cache_set(answer_text, local)\n",
        "        return local\n",
        "\n",
        "    # Gemini（単発呼び出し用に gemini_extract_many を流用）\n",
        "    res = gemini_extract_many([answer_text])\n",
        "    value = res[0] if res else None\n",
        "    _cache_set(answer_text, value)\n",
        "    save_cache()\n",
        "    return value\n",
        "\n",
        "# ==== 5) 評価ループ側での使い方（例） ====\n",
        "# - 既存 evaluate_one_loaded() 内で、SLM生回答 -> extract_numeric_answer() に差し替え\n",
        "# - まとめて抽出したい場合は、バッチ化で gemini_extract_many() を呼ぶ（件数×APIコール削減）\n",
        "\n",
        "# 例: バッチ抽出のフロー（Pseudo）\n",
        "def batch_extract(answers: List[str], batch_size: int = 8) -> List[Optional[str]]:\n",
        "    results = []\n",
        "    batch = []\n",
        "    idxs  = []\n",
        "\n",
        "    # 1) まずキャッシュ/ローカルで埋める\n",
        "    for i, ans in enumerate(answers):\n",
        "        v = _cache_get(ans) or local_numeric_extract(ans)\n",
        "        if v is not None:\n",
        "            _cache_set(ans, v)\n",
        "            results.append(v)\n",
        "        else:\n",
        "            results.append(None)\n",
        "            batch.append(ans)\n",
        "            idxs.append(i)\n",
        "\n",
        "    # 2) Gemini が必要な分だけまとめて投げる\n",
        "    if batch:\n",
        "        gem = gemini_extract_many(batch)\n",
        "        for j, val in enumerate(gem):\n",
        "            i = idxs[j]\n",
        "            results[i] = val\n",
        "            _cache_set(answers[i], val)\n",
        "        save_cache()\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "yJG58HKUy_np"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# === (Colab セル2) 日本語対応のベンチマーク実行（セル1は無改変） ===\n",
        "import math, numpy as np, pandas as pd, unicodedata, re\n",
        "import sacrebleu\n",
        "\n",
        "# セル1で定義済みの以下を利用します:\n",
        "# - LOADED: { model_name: (tokenizer, model) }\n",
        "# - TASKS: タスクリスト\n",
        "# - chat_generate(): 生成関数\n",
        "# - GENCFG: 生成設定\n",
        "# ※ セル1の `scorer` は使わず、セル2内で日本語対応スコアラーを用意します。\n",
        "\n",
        "# ----------------------------\n",
        "# 日本語テキストの前処理 & トークナイザ設定（セル2内完結）\n",
        "# ----------------------------\n",
        "def normalize_ja(s: str) -> str:\n",
        "    # 全角半角の揺れ・不要空白などを吸収（必要に応じて調整）\n",
        "    s = unicodedata.normalize(\"NFKC\", s)\n",
        "    s = s.strip()\n",
        "    return s\n",
        "\n",
        "# fugashi (MeCab) が使えれば単語ベース、無ければ文字ベース\n",
        "try:\n",
        "    from fugashi import Tagger\n",
        "    _tagger = Tagger()\n",
        "    def ja_tokens(text: str):\n",
        "        text = normalize_ja(text)\n",
        "        return [m.surface for m in _tagger(text)]\n",
        "    _bleu_tokenize = \"ja-mecab\"  # sacrebleu の日本語用トークナイザ指定\n",
        "    print(\"Tokenizer for ROUGE: fugashi(MeCab) / BLEU: ja-mecab\")\n",
        "except Exception:\n",
        "    def ja_tokens(text: str):\n",
        "        text = normalize_ja(text)\n",
        "        return list(text)  # 文字ベース\n",
        "    _bleu_tokenize = \"char\"       # 文字ベースBLEU\n",
        "    print(\"Tokenizer for ROUGE: char-level / BLEU: char\")\n",
        "\n",
        "# ----------------------------\n",
        "# ROUGE-L（日本語向け）の実装（セル2内完結）\n",
        "# ----------------------------\n",
        "# rouge_score の内部Tokenizerはセル1で固定されている可能性があるため、\n",
        "# ここではLCSに基づくROUGE-L F1をセル2側で実装します。\n",
        "def _lcs_len(a, b):\n",
        "    # a, b: トークン列\n",
        "    # 動的計画法でLCS長を計算（O(n*m)）\n",
        "    n, m = len(a), len(b)\n",
        "    dp = [0]*(m+1)\n",
        "    for i in range(1, n+1):\n",
        "        prev = 0\n",
        "        for j in range(1, m+1):\n",
        "            tmp = dp[j]\n",
        "            if a[i-1] == b[j-1]:\n",
        "                dp[j] = prev + 1\n",
        "            else:\n",
        "                dp[j] = max(dp[j], dp[j-1])\n",
        "            prev = tmp\n",
        "    return dp[m]\n",
        "\n",
        "def rougeL_f1(ref: str, hyp: str) -> float:\n",
        "    ref_toks = ja_tokens(ref)\n",
        "    hyp_toks = ja_tokens(hyp)\n",
        "    if len(ref_toks) == 0 or len(hyp_toks) == 0:\n",
        "        return 0.0\n",
        "    lcs = _lcs_len(ref_toks, hyp_toks)\n",
        "    prec = lcs / len(hyp_toks)\n",
        "    rec  = lcs / len(ref_toks)\n",
        "    if prec + rec == 0:\n",
        "        return 0.0\n",
        "    f1 = (2 * prec * rec) / (prec + rec)\n",
        "    return float(f1)\n",
        "\n",
        "# ----------------------------\n",
        "# 評価関数（セル1のモデル群を利用）\n",
        "# ----------------------------\n",
        "def evaluate_one_loaded(model_name: str, tok_mdl):\n",
        "    tok, mdl = tok_mdl\n",
        "    rows = []\n",
        "    for task in TASKS:\n",
        "        out, stats = chat_generate(tok, mdl, task[\"messages\"])\n",
        "        # 軽いノイズ除去（任意）：丁寧な前置きのカット例\n",
        "        out_clean = re.sub(r\"^(はい、|承知しました。|以下のとおりです。)+\", \"\", out).strip()\n",
        "        response = extract_numeric_answer(out_clean)\n",
        "                    # client.models.generate_content( model=\"gemini-2.5-pro\",\n",
        "                    # contents=\"次の数式を含む文字列から答えのみ数値として取り出したい．数値だけを出力して．「\"+ out_clean +\"」\" )\n",
        "        out_clean = response\n",
        "        print(out_clean)\n",
        "\n",
        "        row = {\n",
        "            \"model\": model_name,\n",
        "            \"task\": task[\"name\"],\n",
        "            \"output\": out_clean+\"<=\"+out,      # 生出力も保持\n",
        "            **stats\n",
        "        }\n",
        "        # pass@1（セル1定義のjudgeに従う）\n",
        "        if \"judge\" in task:\n",
        "            row[\"pass@1\"] = bool(task[\"judge\"](out_clean))\n",
        "\n",
        "        # ROUGE-L（セル2内で日本語対応計算）\n",
        "        if task.get(\"rougeL\"):\n",
        "            r = rougeL_f1(task[\"ref\"], out_clean)\n",
        "            row[\"ROUGE-L\"] = r\n",
        "\n",
        "        # BLEU（日本語向けトークナイズ設定）\n",
        "        if task.get(\"bleu\"):\n",
        "            bleu = sacrebleu.corpus_bleu(\n",
        "                [normalize_ja(out_clean)],\n",
        "                [[normalize_ja(task[\"ref\"])]],\n",
        "                tokenize=_bleu_tokenize\n",
        "            ).score\n",
        "            row[\"BLEU\"] = bleu\n",
        "\n",
        "        rows.append(row)\n",
        "    return pd.DataFrame(rows)\n",
        "\n",
        "# ----------------------------\n",
        "# 実行\n",
        "# ----------------------------\n",
        "all_dfs = []\n",
        "for name, tok_mdl in LOADED.items():\n",
        "    print(f\"\\n== Evaluating {name} ==\")\n",
        "    df = evaluate_one_loaded(name, tok_mdl)\n",
        "    display(df[[\"model\",\"task\",\"pass@1\",\"ROUGE-L\",\"BLEU\",\"latency_sec\",\"tok_per_sec\",\"output\"]])\n",
        "    all_dfs.append(df)\n",
        "\n",
        "summary = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "# 集計（タスク別の平均）\n",
        "def safe_mean(xs):\n",
        "    xs = [x for x in xs if x is not None and not (isinstance(x, float) and math.isnan(x))]\n",
        "    return float(np.mean(xs)) if xs else float(\"nan\")\n",
        "\n",
        "report = []\n",
        "for m in summary[\"model\"].unique():\n",
        "    sub = summary[summary[\"model\"]==m]\n",
        "    pass_mean = safe_mean([1.0 if x is True else (0.0 if x is False else None) for x in sub.get(\"pass@1\", []).tolist()])\n",
        "    rouge_mean = safe_mean(sub.get(\"ROUGE-L\", []).tolist())\n",
        "    bleu_mean  = safe_mean(sub.get(\"BLEU\", []).tolist())\n",
        "    tps_mean   = safe_mean(sub.get(\"tok_per_sec\", []).tolist())\n",
        "    lat_mean   = safe_mean(sub.get(\"latency_sec\", []).tolist())\n",
        "    report.append({\n",
        "        \"model\": m,\n",
        "        \"pass@1(mean)\": pass_mean,\n",
        "        \"ROUGE-L(mean)\": rouge_mean,\n",
        "        \"BLEU(mean)\": bleu_mean,\n",
        "        \"tok_per_sec(mean)\": tps_mean,\n",
        "        \"latency_sec(mean)\": lat_mean\n",
        "    })\n",
        "\n",
        "print(\"\\n== Summary ==\")\n",
        "display(pd.DataFrame(report))\n",
        "\n",
        "# 生成条件を変更したい場合（任意）\n",
        "# GENCFG.max_new_tokens = 128\n",
        "# GENCFG.temperature = 0.7\n",
        "# GENCFG.do_sample = True\n",
        "# print(\"New GenConfig:\", GENCFG)"
      ],
      "metadata": {
        "id": "QJKX37KblWyZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}